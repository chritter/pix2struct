{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6eea21b3",
      "metadata": {
        "id": "6eea21b3"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google/flax/blob/main/docs/getting_started.ipynb)\n",
        "[![Open On GitHub](https://img.shields.io/badge/Open-on%20GitHub-blue?logo=GitHub)](https://github.com/google/flax/blob/main/docs/getting_started.ipynb)\n",
        "\n",
        "# Getting Started\n",
        "\n",
        "This tutorial demonstrates how to construct a simple convolutional neural\n",
        "network (CNN) using the [Flax](https://flax.readthedocs.io) Linen API and train\n",
        "the network for image classification on the MNIST dataset.\n",
        "\n",
        "Note: This notebook is based on Flax's official\n",
        "[MNIST Example](https://github.com/google/flax/tree/main/examples/mnist).\n",
        "If you see any changes between the two feel free to create a\n",
        "[pull request](https://github.com/google/flax/compare)\n",
        "to synchronize this Colab with the actual example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a31039fb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-01-11T01:04:37.002755Z",
          "iopub.status.busy": "2023-01-11T01:04:37.002333Z",
          "iopub.status.idle": "2023-01-11T01:04:37.694015Z",
          "shell.execute_reply": "2023-01-11T01:04:37.692567Z",
          "shell.execute_reply.started": "2023-01-11T01:04:37.002680Z"
        },
        "id": "a31039fb",
        "outputId": "9b9efff4-16b7-4aa3-adeb-11b62b680fd4",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan 11 13:02:53 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbc9b4f2",
      "metadata": {
        "id": "bbc9b4f2"
      },
      "source": [
        "## 1. Imports\n",
        "\n",
        "Import JAX, [JAX NumPy](https://jax.readthedocs.io/en/latest/jax.numpy.html),\n",
        "Flax, ordinary NumPy, and TensorFlow Datasets (TFDS). Flax can use any\n",
        "data-loading pipeline and this example demonstrates how to utilize TFDS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "bb81587e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-11T01:04:37.698106Z",
          "iopub.status.busy": "2023-01-11T01:04:37.697223Z",
          "iopub.status.idle": "2023-01-11T01:04:37.704546Z",
          "shell.execute_reply": "2023-01-11T01:04:37.703218Z",
          "shell.execute_reply.started": "2023-01-11T01:04:37.698106Z"
        },
        "id": "bb81587e",
        "tags": [
          "skip-execution"
        ],
        "outputId": "fa8543b7-2c89-4b9a-cfb9-bb7e8356bdd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.4/197.4 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.9/154.9 KB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.1/238.1 KB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 KB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#!pip install -r environment.txt\n",
        "!pip install flax -q "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a9633134",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-11T02:10:58.018434Z",
          "iopub.status.busy": "2023-01-11T02:10:58.018006Z",
          "iopub.status.idle": "2023-01-11T02:11:00.183632Z",
          "shell.execute_reply": "2023-01-11T02:11:00.182624Z",
          "shell.execute_reply.started": "2023-01-11T02:10:58.018355Z"
        },
        "id": "a9633134"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp                # JAX NumPy\n",
        "import jaxlib\n",
        "from flax import linen as nn           # The Linen API\n",
        "from flax.training import train_state  # Useful dataclass to keep train state\n",
        "import flax\n",
        "\n",
        "import numpy as np                     # Ordinary NumPy\n",
        "import optax                           # Optimizers\n",
        "import tensorflow_datasets as tfds     # TFDS for MNIST\n",
        "from jax import random\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LVJF07Zv7uIC"
      },
      "id": "LVJF07Zv7uIC",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccab9d57-820c-4841-8482-2542684eb790",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-11T02:11:00.186518Z",
          "iopub.status.busy": "2023-01-11T02:11:00.186087Z",
          "iopub.status.idle": "2023-01-11T02:11:00.199571Z",
          "shell.execute_reply": "2023-01-11T02:11:00.198772Z",
          "shell.execute_reply.started": "2023-01-11T02:11:00.186492Z"
        },
        "id": "ccab9d57-820c-4841-8482-2542684eb790",
        "outputId": "81d84b19-c0ea-4daa-ff0d-d30412eeed19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('0.3.14', '0.5.0', '4.8.1')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jax.__version__, flax.__version__, tfds.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jax.__version__, flax.__version__, tfds.__version__, jaxlib.__version__"
      ],
      "metadata": {
        "id": "7lCbwPgz7ds8",
        "outputId": "360a824a-bad7-4669-c4df-12cd15efd4b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7lCbwPgz7ds8",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('0.3.25', '0.6.3', '4.8.1', '0.3.25')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "041184fc-4484-40b3-a1a6-3171d131aa63",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-11T02:11:00.200879Z",
          "iopub.status.busy": "2023-01-11T02:11:00.200627Z",
          "iopub.status.idle": "2023-01-11T02:11:00.516938Z",
          "shell.execute_reply": "2023-01-11T02:11:00.515799Z",
          "shell.execute_reply.started": "2023-01-11T02:11:00.200854Z"
        },
        "id": "041184fc-4484-40b3-a1a6-3171d131aa63",
        "outputId": "16ae4351-1e69-4405-cf32-690480c75407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "jax.default_backend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7057395a",
      "metadata": {
        "id": "7057395a"
      },
      "source": [
        "## 2. Define network\n",
        "\n",
        "Create a convolutional neural network with the Linen API by subclassing\n",
        "[Module](https://flax.readthedocs.io/en/latest/flax.linen.html#core-module-abstraction).\n",
        "Because the architecture in this example is relatively simple—you're just\n",
        "stacking layers—you can define the inlined submodules directly within the\n",
        "`__call__` method and wrap it with the\n",
        "[@compact](https://flax.readthedocs.io/en/latest/flax.linen.html#compact-methods)\n",
        "decorator. To learn more about the Flax Linen `@compact` decorator, refer to the [`setup` vs `compact`](https://flax.readthedocs.io/en/latest/guides/setup_or_nncompact.html) guide."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "cbc079cd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-11T02:11:00.896618Z",
          "iopub.status.busy": "2023-01-11T02:11:00.896251Z",
          "iopub.status.idle": "2023-01-11T02:11:01.029543Z",
          "shell.execute_reply": "2023-01-11T02:11:01.028730Z",
          "shell.execute_reply.started": "2023-01-11T02:11:00.896591Z"
        },
        "id": "cbc079cd"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "  \"\"\"A simple CNN model.\"\"\"\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "    x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "    x = x.reshape((x.shape[0], -1))  # flatten\n",
        "    x = nn.Dense(features=256)(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(features=10)(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db132446",
      "metadata": {
        "id": "db132446"
      },
      "source": [
        "## 3. Define loss\n",
        "\n",
        "We simply use `optax.softmax_cross_entropy()`. Note that this function expects both `logits` and `labels` to have shape `[batch, num_classes]`. Since the labels will be read from TFDS as integer values, we first need to convert them to a onehot encoding.\n",
        "\n",
        "Our function returns a simple scalar value ready for optimization, so we first take the mean of the vector shaped `[batch]` returned by Optax's loss function."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e895296e-5c05-4629-a6f9-2291e85bd73c",
      "metadata": {
        "id": "e895296e-5c05-4629-a6f9-2291e85bd73c"
      },
      "source": [
        "### Testing the loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "38ef582d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-11T01:04:40.029117Z",
          "iopub.status.busy": "2023-01-11T01:04:40.028267Z",
          "iopub.status.idle": "2023-01-11T01:04:40.034552Z",
          "shell.execute_reply": "2023-01-11T01:04:40.033266Z",
          "shell.execute_reply.started": "2023-01-11T01:04:40.029117Z"
        },
        "id": "38ef582d"
      },
      "outputs": [],
      "source": [
        "def cross_entropy_loss(*, logits, labels):\n",
        "  labels_onehot = jax.nn.one_hot(labels, num_classes=10)\n",
        "  return optax.softmax_cross_entropy(logits=logits, labels=labels_onehot).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6bc120f7-73ff-47c3-8e60-a094b815c06f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-11T01:04:40.036389Z",
          "iopub.status.busy": "2023-01-11T01:04:40.036389Z",
          "iopub.status.idle": "2023-01-11T01:04:40.570057Z",
          "shell.execute_reply": "2023-01-11T01:04:40.568765Z",
          "shell.execute_reply.started": "2023-01-11T01:04:40.036389Z"
        },
        "id": "6bc120f7-73ff-47c3-8e60-a094b815c06f",
        "outputId": "a30fb4a2-3979-4945-93c6-45927ca3af9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "             [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "             [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "labels = jnp.ones((3))\n",
        "logits = jnp.ones((3, 1))\n",
        "\n",
        "jax.nn.one_hot(labels, num_classes=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "69de32f9-78a2-4c67-bdcb-bc2ef3287478",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-11T01:04:40.571297Z",
          "iopub.status.busy": "2023-01-11T01:04:40.570960Z",
          "iopub.status.idle": "2023-01-11T01:04:40.578820Z",
          "shell.execute_reply": "2023-01-11T01:04:40.577654Z",
          "shell.execute_reply.started": "2023-01-11T01:04:40.571243Z"
        },
        "id": "69de32f9-78a2-4c67-bdcb-bc2ef3287478",
        "outputId": "573e5c84-bab3-4b32-cbf0-e15e1c5815d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "jax.nn.one_hot(labels, num_classes=10).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "064658f8-a671-4b24-8a13-3cce8da21c4a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-11T01:04:40.580098Z",
          "iopub.status.busy": "2023-01-11T01:04:40.579820Z",
          "iopub.status.idle": "2023-01-11T01:04:41.000547Z",
          "shell.execute_reply": "2023-01-11T01:04:40.999787Z",
          "shell.execute_reply.started": "2023-01-11T01:04:40.580074Z"
        },
        "id": "064658f8-a671-4b24-8a13-3cce8da21c4a",
        "outputId": "b4e61e17-f9a1-40e8-901f-9c854dad2cc7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DeviceArray(0., dtype=float32)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cross_entropy_loss(logits=logits, labels=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ff5145f",
      "metadata": {
        "id": "0ff5145f"
      },
      "source": [
        "## 4. Metric computation\n",
        "\n",
        "For loss and accuracy metrics, create a separate function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fc8d0f3-52e7-4d56-8805-6ef9f3ffdf50",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-11T02:11:12.912592Z",
          "iopub.status.busy": "2023-01-11T02:11:12.912052Z",
          "iopub.status.idle": "2023-01-11T02:11:13.925650Z",
          "shell.execute_reply": "2023-01-11T02:11:13.924596Z",
          "shell.execute_reply.started": "2023-01-11T02:11:12.912549Z"
        },
        "id": "8fc8d0f3-52e7-4d56-8805-6ef9f3ffdf50",
        "outputId": "595d0a6f-c0a2-4265-89ef-fcbe52f2f98b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DeviceArray([[ 1.3471218, -2.4386218],\n",
              "             [-0.5627899,  1.1791298]], dtype=float32)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_test = random.normal(random.PRNGKey(10), (2,2))\n",
        "random_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "9bef1169-b348-4f11-9d78-eb78478cf571",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-11T02:11:13.927379Z",
          "iopub.status.busy": "2023-01-11T02:11:13.927125Z",
          "iopub.status.idle": "2023-01-11T02:11:14.033127Z",
          "shell.execute_reply": "2023-01-11T02:11:14.032286Z",
          "shell.execute_reply.started": "2023-01-11T02:11:13.927354Z"
        },
        "id": "9bef1169-b348-4f11-9d78-eb78478cf571",
        "outputId": "59b8783f-8ea3-4a2b-abc5-e1b3c3d521af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-d68e0853d78f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'random_test' is not defined"
          ]
        }
      ],
      "source": [
        "jnp.argmax(random_test, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "961bf70b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-11T02:11:23.855656Z",
          "iopub.status.busy": "2023-01-11T02:11:23.855207Z",
          "iopub.status.idle": "2023-01-11T02:11:23.862766Z",
          "shell.execute_reply": "2023-01-11T02:11:23.861361Z",
          "shell.execute_reply.started": "2023-01-11T02:11:23.855609Z"
        },
        "id": "961bf70b"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(*, logits, labels):\n",
        "  loss = cross_entropy_loss(logits=logits, labels=labels)\n",
        "  accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
        "  metrics = {\n",
        "      'loss': loss,\n",
        "      'accuracy': accuracy,\n",
        "  }\n",
        "  return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b529fbef",
      "metadata": {
        "id": "b529fbef"
      },
      "source": [
        "## 5. Loading data\n",
        "\n",
        "Define a function that loads and prepares the MNIST dataset and converts the\n",
        "samples to floating-point numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c890459",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-11T02:11:25.934458Z",
          "iopub.status.busy": "2023-01-11T02:11:25.934087Z",
          "iopub.status.idle": "2023-01-11T02:11:25.940857Z",
          "shell.execute_reply": "2023-01-11T02:11:25.939590Z",
          "shell.execute_reply.started": "2023-01-11T02:11:25.934432Z"
        },
        "id": "8c890459"
      },
      "outputs": [],
      "source": [
        "def get_datasets():\n",
        "  \"\"\"Load MNIST train and test datasets into memory.\"\"\"\n",
        "  ds_builder = tfds.builder('mnist')\n",
        "  ds_builder.download_and_prepare()\n",
        "  train_ds = tfds.as_numpy(ds_builder.as_dataset(split='train', batch_size=-1))\n",
        "  test_ds = tfds.as_numpy(ds_builder.as_dataset(split='test', batch_size=-1))\n",
        "  train_ds['image'] = jnp.float32(train_ds['image']) / 255.\n",
        "  test_ds['image'] = jnp.float32(test_ds['image']) / 255.\n",
        "  return train_ds, test_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad3ed51d-3466-457a-ae10-37541c424304",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-11T02:11:26.485452Z",
          "iopub.status.busy": "2023-01-11T02:11:26.485084Z",
          "iopub.status.idle": "2023-01-11T02:11:32.643515Z",
          "shell.execute_reply": "2023-01-11T02:11:32.642689Z",
          "shell.execute_reply.started": "2023-01-11T02:11:26.485425Z"
        },
        "id": "ad3ed51d-3466-457a-ae10-37541c424304"
      },
      "outputs": [],
      "source": [
        "train_ds, test_ds = get_datasets()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf0067e6-1e57-45c6-bedf-fb91bf6462d0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-11T02:11:32.645741Z",
          "iopub.status.busy": "2023-01-11T02:11:32.644813Z",
          "iopub.status.idle": "2023-01-11T02:11:32.650624Z",
          "shell.execute_reply": "2023-01-11T02:11:32.649966Z",
          "shell.execute_reply.started": "2023-01-11T02:11:32.645714Z"
        },
        "id": "bf0067e6-1e57-45c6-bedf-fb91bf6462d0",
        "outputId": "2b4add34-bafd-4464-ec99-983f0e7734ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['image', 'label'])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d783adf-c065-4528-abe5-11101a55ca36",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-11T02:11:32.652103Z",
          "iopub.status.busy": "2023-01-11T02:11:32.651293Z",
          "iopub.status.idle": "2023-01-11T02:11:32.657761Z",
          "shell.execute_reply": "2023-01-11T02:11:32.657142Z",
          "shell.execute_reply.started": "2023-01-11T02:11:32.652077Z"
        },
        "id": "5d783adf-c065-4528-abe5-11101a55ca36",
        "outputId": "88715c94-d550-4a82-d736-9f0cee095dc6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((60000, 28, 28, 1), (10000, 28, 28, 1))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds['image'].shape, test_ds['image'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b5ac16e",
      "metadata": {
        "id": "4b5ac16e"
      },
      "source": [
        "## 6. Create train state\n",
        "\n",
        "A common pattern in Flax is to create a single dataclass that represents the\n",
        "entire training state, including step number, parameters, and optimizer state.\n",
        "\n",
        "Also adding optimizer & model to this state has the advantage that we only need\n",
        "to pass around a single argument to functions like `train_step()` (see below).\n",
        "\n",
        "Because this is such a common pattern, Flax provides the class\n",
        "[flax.training.train_state.TrainState](https://flax.readthedocs.io/en/latest/flax.training.html#train-state)\n",
        "that serves most basic usecases. Usually one would subclass it to add more data\n",
        "to be tracked, but in this example we can use it without any modifications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0102447",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-11T02:11:50.065604Z",
          "iopub.status.busy": "2023-01-11T02:11:50.064155Z",
          "iopub.status.idle": "2023-01-11T02:11:50.071092Z",
          "shell.execute_reply": "2023-01-11T02:11:50.070259Z",
          "shell.execute_reply.started": "2023-01-11T02:11:50.065557Z"
        },
        "id": "e0102447"
      },
      "outputs": [],
      "source": [
        "def create_train_state(rng, learning_rate, momentum):\n",
        "  \"\"\"Creates initial `TrainState`.\"\"\"\n",
        "  cnn = CNN()\n",
        "  params = cnn.init(rng, jnp.ones([1, 28, 28, 1]))['params'] # initialize parameters by passing a template image\n",
        "  tx = optax.sgd(learning_rate, momentum)\n",
        "  return train_state.TrainState.create(\n",
        "      apply_fn=cnn.apply, params=params, tx=tx)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a15de484",
      "metadata": {
        "id": "a15de484"
      },
      "source": [
        "## 7. Training step\n",
        "\n",
        "A function that:\n",
        "\n",
        "- Evaluates the neural network given the parameters and a batch of input images\n",
        "  with the\n",
        "  [Module.apply](https://flax.readthedocs.io/en/latest/flax.linen.html#flax.linen.Module.apply)\n",
        "  method (forward pass).\n",
        "- Computes the `cross_entropy_loss` loss function.\n",
        "- Evaluates the gradient of the loss function using\n",
        "  [jax.grad](https://jax.readthedocs.io/en/latest/jax.html#jax.grad).\n",
        "- Applies a\n",
        "  [pytree](https://jax.readthedocs.io/en/latest/pytrees.html#pytrees-and-jax-functions)\n",
        "  of gradients to the optimizer to update the model's parameters.\n",
        "- Computes the metrics using `compute_metrics` (defined earlier).\n",
        "\n",
        "Use JAX's [@jit](https://jax.readthedocs.io/en/latest/jax.html#jax.jit)\n",
        "decorator to trace the entire `train_step` function and just-in-time compile\n",
        "it with [XLA](https://www.tensorflow.org/xla) into fused device operations\n",
        "that run faster and more efficiently on hardware accelerators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b0af486",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-11T02:11:57.232595Z",
          "iopub.status.busy": "2023-01-11T02:11:57.228758Z",
          "iopub.status.idle": "2023-01-11T02:11:57.239324Z",
          "shell.execute_reply": "2023-01-11T02:11:57.238018Z",
          "shell.execute_reply.started": "2023-01-11T02:11:57.232565Z"
        },
        "id": "9b0af486"
      },
      "outputs": [],
      "source": [
        "@jax.jit\n",
        "def train_step(state, batch):\n",
        "  \"\"\"Train for a single step.\"\"\"\n",
        "  def loss_fn(params):\n",
        "    logits = CNN().apply({'params': params}, batch['image'])\n",
        "    loss = cross_entropy_loss(logits=logits, labels=batch['label'])\n",
        "    return loss, logits\n",
        "  grad_fn = jax.grad(loss_fn, has_aux=True)\n",
        "  grads, logits = grad_fn(state.params)\n",
        "  state = state.apply_gradients(grads=grads)\n",
        "  metrics = compute_metrics(logits=logits, labels=batch['label'])\n",
        "  return state, metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e516091",
      "metadata": {
        "id": "4e516091"
      },
      "source": [
        "## 8. Evaluation step\n",
        "\n",
        "Create a function that evaluates your model on the test set with\n",
        "[Module.apply](https://flax.readthedocs.io/en/latest/flax.linen.html#flax.linen.Module.apply)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31f872b3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-11T02:11:59.502035Z",
          "iopub.status.busy": "2023-01-11T02:11:59.500710Z",
          "iopub.status.idle": "2023-01-11T02:11:59.507073Z",
          "shell.execute_reply": "2023-01-11T02:11:59.506225Z",
          "shell.execute_reply.started": "2023-01-11T02:11:59.501990Z"
        },
        "id": "31f872b3"
      },
      "outputs": [],
      "source": [
        "@jax.jit\n",
        "def eval_step(params, batch):\n",
        "  logits = CNN().apply({'params': params}, batch['image'])\n",
        "  return compute_metrics(logits=logits, labels=batch['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1adc0b23",
      "metadata": {
        "id": "1adc0b23"
      },
      "source": [
        "## 9. Train function\n",
        "\n",
        "Define a training function that:\n",
        "\n",
        "- Shuffles the training data before each epoch using\n",
        "  [jax.random.permutation](https://jax.readthedocs.io/en/latest/_autosummary/jax.random.permutation.html)\n",
        "  that takes a PRNGKey as a parameter (check the\n",
        "  [JAX - the sharp bits](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#JAX-PRNG)).\n",
        "- Runs an optimization step for each batch.\n",
        "- Asynchronously retrieves the training metrics from the device with `jax.device_get` and\n",
        "  computes their mean across each batch in an epoch.\n",
        "- Returns the optimizer with updated parameters and the training loss and\n",
        "  accuracy metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9ef05a2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-11T02:12:02.381894Z",
          "iopub.status.busy": "2023-01-11T02:12:02.380980Z",
          "iopub.status.idle": "2023-01-11T02:12:02.390196Z",
          "shell.execute_reply": "2023-01-11T02:12:02.388999Z",
          "shell.execute_reply.started": "2023-01-11T02:12:02.381865Z"
        },
        "id": "e9ef05a2"
      },
      "outputs": [],
      "source": [
        "def train_epoch(state, train_ds, batch_size, epoch, rng):\n",
        "  \"\"\"Train for a single epoch.\"\"\"\n",
        "  train_ds_size = len(train_ds['image'])\n",
        "  steps_per_epoch = train_ds_size // batch_size\n",
        "\n",
        "  perms = jax.random.permutation(rng, train_ds_size) # get a randomized index array\n",
        "  perms = perms[:steps_per_epoch * batch_size]  # skip incomplete batch\n",
        "  perms = perms.reshape((steps_per_epoch, batch_size)) # index array, where each row is a batch\n",
        "  batch_metrics = []\n",
        "  for perm in perms:\n",
        "    batch = {k: v[perm, ...] for k, v in train_ds.items()} # dict{'image': array, 'label': array}\n",
        "    state, metrics = train_step(state, batch)\n",
        "    batch_metrics.append(metrics)\n",
        "\n",
        "  # compute mean of metrics across each batch in epoch.\n",
        "  batch_metrics_np = jax.device_get(batch_metrics)\n",
        "  epoch_metrics_np = {\n",
        "      k: np.mean([metrics[k] for metrics in batch_metrics_np])\n",
        "      for k in batch_metrics_np[0]} # jnp.mean does not work on lists\n",
        "\n",
        "  print('train epoch: %d, loss: %.4f, accuracy: %.2f' % (\n",
        "      epoch, epoch_metrics_np['loss'], epoch_metrics_np['accuracy'] * 100))\n",
        "\n",
        "  return state"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f81f31e",
      "metadata": {
        "id": "7f81f31e"
      },
      "source": [
        "## 10. Eval function\n",
        "\n",
        "Create a model evaluation function that:\n",
        "\n",
        "- Retrieves the evaluation metrics from the device with `jax.device_get`.\n",
        "- Copies the metrics\n",
        "  [data stored](https://flax.readthedocs.io/en/latest/design_notes/linen_design_principles.html#how-are-parameters-represented-and-how-do-we-handle-general-differentiable-algorithms-that-update-stateful-variables)\n",
        "  in a JAX\n",
        "  [pytree](https://jax.readthedocs.io/en/latest/pytrees.html#pytrees-and-jax-functions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09c3f6b6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-11T02:12:05.187099Z",
          "iopub.status.busy": "2023-01-11T02:12:05.185935Z",
          "iopub.status.idle": "2023-01-11T02:12:05.193643Z",
          "shell.execute_reply": "2023-01-11T02:12:05.192294Z",
          "shell.execute_reply.started": "2023-01-11T02:12:05.187057Z"
        },
        "id": "09c3f6b6"
      },
      "outputs": [],
      "source": [
        "def eval_model(params, test_ds):\n",
        "  metrics = eval_step(params, test_ds)\n",
        "  metrics = jax.device_get(metrics)\n",
        "  summary = jax.tree_util.tree_map(lambda x: x.item(), metrics) # map the function over all leaves in metrics\n",
        "  return summary['loss'], summary['accuracy']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "497241c3",
      "metadata": {
        "id": "497241c3"
      },
      "source": [
        "## 11. Download data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bff5393e",
      "metadata": {
        "id": "bff5393e"
      },
      "outputs": [],
      "source": [
        "# train_ds, test_ds = get_datasets()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "809ae1a0",
      "metadata": {
        "id": "809ae1a0"
      },
      "source": [
        "## 12. Seed randomness\n",
        "\n",
        "- Get one\n",
        "  [PRNGKey](https://jax.readthedocs.io/en/latest/_autosummary/jax.random.PRNGKey.html#jax.random.PRNGKey)\n",
        "  and\n",
        "  [split](https://jax.readthedocs.io/en/latest/_autosummary/jax.random.split.html#jax.random.split)\n",
        "  it to get a second key that you'll use for parameter initialization. (Learn\n",
        "  more about\n",
        "  [PRNG chains](https://flax.readthedocs.io/en/latest/design_notes/linen_design_principles.html#how-are-parameters-represented-and-how-do-we-handle-general-differentiable-algorithms-that-update-stateful-variables)\n",
        "  and\n",
        "  [JAX PRNG design](https://jax.readthedocs.io/en/latest/jax-101/05-random-numbers.html).)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4f6f4d3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-11T02:12:10.551192Z",
          "iopub.status.busy": "2023-01-11T02:12:10.550835Z",
          "iopub.status.idle": "2023-01-11T02:12:10.736552Z",
          "shell.execute_reply": "2023-01-11T02:12:10.735660Z",
          "shell.execute_reply.started": "2023-01-11T02:12:10.551167Z"
        },
        "id": "e4f6f4d3"
      },
      "outputs": [],
      "source": [
        "rng = jax.random.PRNGKey(0)\n",
        "rng, init_rng = jax.random.split(rng)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80fbb60b",
      "metadata": {
        "id": "80fbb60b"
      },
      "source": [
        "## 13. Initialize train state\n",
        "\n",
        "Remember that function initializes both the model parameters and the optimizer\n",
        "and puts both into the training state dataclass that is returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "445fcab0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-11T02:12:15.056505Z",
          "iopub.status.busy": "2023-01-11T02:12:15.055560Z",
          "iopub.status.idle": "2023-01-11T02:12:15.060929Z",
          "shell.execute_reply": "2023-01-11T02:12:15.059972Z",
          "shell.execute_reply.started": "2023-01-11T02:12:15.056475Z"
        },
        "id": "445fcab0"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.1\n",
        "momentum = 0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "528f519f-ffd8-4136-b60c-61aee46ef1c7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-11T02:14:12.043375Z",
          "iopub.status.busy": "2023-01-11T02:14:12.043007Z",
          "iopub.status.idle": "2023-01-11T02:14:13.507625Z",
          "shell.execute_reply": "2023-01-11T02:14:13.506067Z",
          "shell.execute_reply.started": "2023-01-11T02:14:12.043347Z"
        },
        "id": "528f519f-ffd8-4136-b60c-61aee46ef1c7"
      },
      "outputs": [],
      "source": [
        "\n",
        "!export XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
        "!export XLA_FLAGS=\"--xla_gpu_strict_conv_algorithm_picker=false --xla_gpu_force_compilation_parallelism=1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5221eafd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-01-11T02:14:16.580194Z",
          "iopub.status.busy": "2023-01-11T02:14:16.578987Z",
          "iopub.status.idle": "2023-01-11T02:14:16.700450Z",
          "shell.execute_reply": "2023-01-11T02:14:16.698859Z",
          "shell.execute_reply.started": "2023-01-11T02:14:16.580158Z"
        },
        "id": "5221eafd",
        "outputId": "3535a1c5-43f8-4c54-9800-98181706aff8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-01-11 02:14:16.619694: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc:377] Loaded runtime CuDNN library: 8.1.1 but source was compiled with: 8.2.4.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
            "2023-01-11 02:14:16.625186: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc:377] Loaded runtime CuDNN library: 8.1.1 but source was compiled with: 8.2.4.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
            "2023-01-11 02:14:16.627234: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_dnn.cc:377] Loaded runtime CuDNN library: 8.1.1 but source was compiled with: 8.2.4.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n"
          ]
        },
        {
          "ename": "XlaRuntimeError",
          "evalue": "UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n%cudnn-conv = (f32[1,28,28,32]{2,1,3,0}, u8[0]{0}) custom-call(f32[1,28,28,1]{2,1,3,0} %bitcast, f32[3,3,1,32]{1,0,2,3} %copy.1), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target=\"__cudnn$convForward\", metadata={op_name=\"jit(conv_general_dilated)/jit(main)/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(1, 28, 28, 1) rhs_shape=(3, 3, 1, 32) precision=None preferred_element_type=None]\" source_file=\"/usr/local/lib/python3.9/dist-packages/flax/linen/linear.py\" source_line=406}, backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\"\n\nOriginal error: UNIMPLEMENTED: DNN library is not found.\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
            "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_train_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_rng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m init_rng\n",
            "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mcreate_train_state\u001b[0;34m(rng, learning_rate, momentum)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"Creates initial `TrainState`.\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m cnn \u001b[38;5;241m=\u001b[39m CNN()\n\u001b[0;32m----> 4\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43mcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m# initialize parameters by passing a template image\u001b[39;00m\n\u001b[1;32m      5\u001b[0m tx \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39msgd(learning_rate, momentum)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_state\u001b[38;5;241m.\u001b[39mTrainState\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      7\u001b[0m     apply_fn\u001b[38;5;241m=\u001b[39mcnn\u001b[38;5;241m.\u001b[39mapply, params\u001b[38;5;241m=\u001b[39mparams, tx\u001b[38;5;241m=\u001b[39mtx)\n",
            "    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n",
            "File \u001b[0;32m/usr/lib/python3.9/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
            "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mCNN.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;129m@nn\u001b[39m\u001b[38;5;241m.\u001b[39mcompact\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m----> 6\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m   x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m      8\u001b[0m   x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mavg_pool(x, window_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m), strides\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "File \u001b[0;32m/usr/lib/python3.9/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/flax/linen/linear.py:406\u001b[0m, in \u001b[0;36m_Conv.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    404\u001b[0m inputs, kernel, bias \u001b[38;5;241m=\u001b[39m promote_dtype(inputs, kernel, bias, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshared_weights:\n\u001b[0;32m--> 406\u001b[0m   y \u001b[38;5;241m=\u001b[39m \u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_general_dilated\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpadding_lax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlhs_dilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m      \u001b[49m\u001b[43mrhs_dilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel_dilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdimension_numbers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdimension_numbers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfeature_group_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_group_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m      \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m   y \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39mconv_general_dilated_local(\n\u001b[1;32m    419\u001b[0m       lhs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    420\u001b[0m       rhs\u001b[38;5;241m=\u001b[39mkernel,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    427\u001b[0m       precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision\n\u001b[1;32m    428\u001b[0m   )\n",
            "    \u001b[0;31m[... skipping hidden 13 frame]\u001b[0m\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/jax/_src/dispatch.py:818\u001b[0m, in \u001b[0;36mbackend_compile\u001b[0;34m(backend, built_c, options)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;129m@profiler\u001b[39m\u001b[38;5;241m.\u001b[39mannotate_function\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackend_compile\u001b[39m(backend, built_c, options):\n\u001b[1;32m    816\u001b[0m   \u001b[38;5;66;03m# we use a separate function call to ensure that XLA compilation appears\u001b[39;00m\n\u001b[1;32m    817\u001b[0m   \u001b[38;5;66;03m# separately in Python profiling results\u001b[39;00m\n\u001b[0;32m--> 818\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilt_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mXlaRuntimeError\u001b[0m: UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n%cudnn-conv = (f32[1,28,28,32]{2,1,3,0}, u8[0]{0}) custom-call(f32[1,28,28,1]{2,1,3,0} %bitcast, f32[3,3,1,32]{1,0,2,3} %copy.1), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target=\"__cudnn$convForward\", metadata={op_name=\"jit(conv_general_dilated)/jit(main)/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(1, 28, 28, 1) rhs_shape=(3, 3, 1, 32) precision=None preferred_element_type=None]\" source_file=\"/usr/local/lib/python3.9/dist-packages/flax/linen/linear.py\" source_line=406}, backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\"\n\nOriginal error: UNIMPLEMENTED: DNN library is not found.\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning."
          ]
        }
      ],
      "source": [
        "state = create_train_state(init_rng, learning_rate, momentum)\n",
        "del init_rng  # Must not be used anymore."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1c00230",
      "metadata": {
        "id": "b1c00230"
      },
      "source": [
        "## 14. Train and evaluate\n",
        "\n",
        "Once the training and testing is done after 10 epochs, the output should show that your model was able to achieve approximately 99% accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74295360",
      "metadata": {
        "id": "74295360"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c40ce90",
      "metadata": {
        "id": "2c40ce90"
      },
      "outputs": [],
      "source": [
        "for epoch in range(1, num_epochs + 1):\n",
        "  # Use a separate PRNG key to permute image data during shuffling\n",
        "  rng, input_rng = jax.random.split(rng)\n",
        "  # Run an optimization step over a training batch\n",
        "  state = train_epoch(state, train_ds, batch_size, epoch, input_rng)\n",
        "  # Evaluate on the test set after each training epoch\n",
        "  test_loss, test_accuracy = eval_model(state.params, test_ds)\n",
        "  print(' test epoch: %d, loss: %.2f, accuracy: %.2f' % (\n",
        "      epoch, test_loss, test_accuracy * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edb528b6",
      "metadata": {
        "id": "edb528b6"
      },
      "source": [
        "Congrats! You made it to the end of the annotated MNIST example. You can revisit\n",
        "the same example, but structured differently as a couple of Python modules, test\n",
        "modules, config files, another Colab, and documentation in Flax's Git repo:\n",
        "\n",
        "[https://github.com/google/flax/tree/main/examples/mnist](https://github.com/google/flax/tree/main/examples/mnist)"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "formats": "ipynb,md:myst",
      "main_language": "python"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}